---
title: "Stacking methods in mlr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Recently stacking got quite famous mainly due to some very successful kaggle competitions[^1][^2][^3]. The fundamental idea to stack (or combine) methods is that many very good algorithms should perform better than just a single one. 

This vignette should serve as an overview of stacking methods which are already implemented in mlr. It contains information about the methods, pros and cons, and furthermore same example code.

Currently this methods are available:

* `average`
* `stack.nocv`
* `stack.cv`
* `hill.climb` 
* `compress`
* `boost.stack`

The basis of stacking are the base models created by differnet machine learning algorithm (e.g. some SVM, ANN, GBM). The stacking methods now determine how these base models are going to be combined/aggregated. The first method (`average`) just compute the average over all used models, whereas `stack.nocv` and `stack.cv` use classification/regression models to aggregate the underlying base models. They differ in the kind the predictions are produced: `stack.nocv` trains the model on the whole data set and then makes predictions, while `stack.cv` uses crossvalidation. `hill.climb` (also know as "Ensebmle selection") uses a greedy stepwise-forward search to select only the best models. This method has further parameters which are will be fully explained in the lower section. `compress` is build on top of `hill.climb` and ....
The last method is `boost.stack` ("Boosted Stacking") which iteratively adds predictions as feature to the data set. The predictions are made by "good" models created my random search. The idea is that the new predictions act like high-class features, which improve over time. 

<!--  #, i.e. `init` which specify the number of best models who are inclued in the ensemble before stepwise selection is done, `replace` which indicated if models could be added several times, `` --> 


## Averaging

Text 

**Pros**

* Computational the simplest method
* May perform well when few very good base models are used

**Cons**

* Perform poorly when bad models are presend (e.g. when base models are generated by grid search)

## Stacking with classification/regression models and without crossvalidation

## Stacking with classification/regression models and with crossvalidation

## Ensemble selection 

## Compress

## Boosted Stacking


[^1]: http://mlwave.com/kaggle-ensembling-guide/
[^2]: http://blog.kaggle.com/2016/04/08/homesite-quote-conversion-winners-write-up-1st-place-kazanova-faron-clobber/
[^3]: http://blog.kaggle.com/2016/03/17/airbnb-new-user-bookings-winners-interview-2nd-place-keiichi-kuroyanagi-keiku/