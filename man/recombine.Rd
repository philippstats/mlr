% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StackedLearner_recombine.R
\name{recombine}
\alias{recombine}
\title{Recombine stacking with new super.learner or new parset for "ens.sel". This is in alpha.}
\usage{
recombine(id = NULL, obj, task, measures = NULL, super.learner = NULL,
  use.feat = NULL, parset = NULL)
}
\arguments{
\item{id}{[\code{character(1)}]\cr Id.}

\item{obj}{[\code{ResampleResult}]\cr Object using \code{StackedLearner} as Learner.}

\item{task}{[\code{\link{Task}}]\cr
The task.}

\item{measures}{[\code{\link{Measure}} | list of \code{\link{Measure}}]\cr
Performance measure(s) to evaluate.
Default is the default measure for the task, see here \code{\link{getDefaultMeasure}}.}

\item{super.learner}{[\code{Learner}]\cr New \code{super.learner} to apply.}

\item{use.feat}{[\code{logical(1)}]\cr Whether the original features should also be passed to the super learner.}

\item{parset}{[\code{list}]\cr List containing parameter for \code{hill.climb}. See \code{\link{makeStackedLearner}}.}
}
\description{
Instead of compute a whole new resampling procedure just use \code{recombine}. 
\code{recombine} reuse the already done work from \code{resample}, i.e. 
reuse already fitted base models and reuse level 1 data. Note: This function 
does not support resample objects with single broken base models (no error 
handling). Moreover models need to present (i.e. save.preds = TRUE in 
akeStackedLearner). 
This function does three things internally to obtain the new predictions.
1. Obtain Level 1 Data for training set. This is needed to train new superlearner 
or new ensemble selection.
2. Train superlearner or ensemble selection using level 1 data.
3. Create Level 1 Data for the test set (may be several test sets in case of CV),
i.e. predict with saved models and test data. Returned Predictions are Level 1 Data.
4. Apply model from (2) on Level 1 Data from (3).
}
\examples{
tsk = pid.task
bls = list(makeLearner("classif.kknn", id = "k1"), 
  makeLearner("classif.randomForest", id = "f1"),
  makeLearner("classif.rpart", id = "r1", minsplit = 5),
  makeLearner("classif.rpart", id = "r2", minsplit = 10),
  makeLearner("classif.rpart", id = "r3", minsplit = 15),
  makeLearner("classif.rpart", id = "r4", minsplit = 20),
  makeLearner("classif.rpart", id = "r5", minsplit = 25)
)
bls = lapply(BLS, function(x) setPredictType(x, predict.type = "prob"))
ste = makeStackedLearner(id = "stack", bls, resampling = cv3, 
  predict.type = "prob", method = "hill.climb", parset = list(init = 1, 
  bagprob = 0.5, bagtime = 3, metric = mmce))
resres = resample(ste, tsk, cv5, models = TRUE) 
re2 = recombine(obj = resres, task = tsk, parset = list(init = 2))
re3 = recombine(obj = resres, task = tsk, measures = list(mmce), parset = list(prob = .2))
re3 = recombine(obj = resres, task = tsk, measures = mmce, parset = list(prob = .2))
re4 = recombine(obj = resres, task = tsk, measures = list(acc), parset = list(bagtime = 10))
re5 = recombine(obj = resres, task = tsk, measures = list(mmce, acc), parset = list(init = 2, prob = .7, bagtime = 10))

sapply(list(resres, re2, re3, re4, re5), function(x) x$runtime)
sapply(list(resres, re2, re3, re4, re5), function(x) x$aggr)
}

